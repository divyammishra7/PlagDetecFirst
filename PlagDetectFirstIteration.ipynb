{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159e678f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\cmudict.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\gutenberg.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\inaugural.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\names.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\shakespeare.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\words.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\91991\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"popular\")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54fc431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"article.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d09ffac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_text</th>\n",
       "      <th>plagiarized_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Researchers have discovered a new species of b...</td>\n",
       "      <td>Scientists have found a previously unknown but...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The moon orbits the Earth in approximately 27....</td>\n",
       "      <td>Our natural satellite takes around 27.3 days t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Water is composed of two hydrogen atoms and on...</td>\n",
       "      <td>H2O consists of 2 hydrogen atoms and 1 oxygen ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The history of Rome dates back to 753 BC.</td>\n",
       "      <td>Rome has a long history that can be traced bac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pluto was once considered the ninth planet in ...</td>\n",
       "      <td>In the past, Pluto was classified as the ninth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This is a unique and original sentence.</td>\n",
       "      <td>This sentence is unique and original.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Artificial intelligence is reshaping industries.</td>\n",
       "      <td>AI is changing the landscape of various sectors.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Python is a popular programming language for d...</td>\n",
       "      <td>Data science often relies on Python as a widel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Earth revolves around the Sun in a nearly ...</td>\n",
       "      <td>Our planet follows an almost circular path as ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Paris is the capital of France.</td>\n",
       "      <td>France's capital city is Paris.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_text  \\\n",
       "0  Researchers have discovered a new species of b...   \n",
       "1  The moon orbits the Earth in approximately 27....   \n",
       "2  Water is composed of two hydrogen atoms and on...   \n",
       "3          The history of Rome dates back to 753 BC.   \n",
       "4  Pluto was once considered the ninth planet in ...   \n",
       "5            This is a unique and original sentence.   \n",
       "6   Artificial intelligence is reshaping industries.   \n",
       "7  Python is a popular programming language for d...   \n",
       "8  The Earth revolves around the Sun in a nearly ...   \n",
       "9                    Paris is the capital of France.   \n",
       "\n",
       "                                    plagiarized_text  label  \n",
       "0  Scientists have found a previously unknown but...      1  \n",
       "1  Our natural satellite takes around 27.3 days t...      1  \n",
       "2  H2O consists of 2 hydrogen atoms and 1 oxygen ...      1  \n",
       "3  Rome has a long history that can be traced bac...      1  \n",
       "4  In the past, Pluto was classified as the ninth...      1  \n",
       "5              This sentence is unique and original.      0  \n",
       "6   AI is changing the landscape of various sectors.      0  \n",
       "7  Data science often relies on Python as a widel...      0  \n",
       "8  Our planet follows an almost circular path as ...      0  \n",
       "9                    France's capital city is Paris.      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b471d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = \" \".join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "data[\"source_text\"] = data[\"source_text\"].apply(preprocess_text)\n",
    "data[\"plagiarized_text\"] = data[\"plagiarized_text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1988729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    researchers discovered new species butterfly a...\n",
       "1             moon orbits earth approximately 273 days\n",
       "2    water composed two hydrogen atoms one oxygen atom\n",
       "3                       history rome dates back 753 bc\n",
       "4           pluto considered ninth planet solar system\n",
       "5                             unique original sentence\n",
       "6         artificial intelligence reshaping industries\n",
       "7     python popular programming language data science\n",
       "8      earth revolves around sun nearly circular orbit\n",
       "9                                 paris capital france\n",
       "Name: source_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"source_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d3a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(data[\"source_text\"] + \" \" + data[\"plagiarized_text\"])\n",
    "y = data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eab997e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb435079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plagiarism_model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'plagiarism_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb346134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is plagiarized with a similarity score of 61.72%.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load('plagiarism_model.pkl')\n",
    "\n",
    "# New text for plagiarism detection\n",
    "new_text = \"A new group of researchers found out a new class of butterfly in the Amazon forest of rain.\"\n",
    "\n",
    "# Preprocess the new text (e.g., apply the same preprocessing steps as during training)\n",
    "new_text = preprocess_text(new_text)\n",
    "\n",
    "# Convert the preprocessed text into TF-IDF vectors (assuming you have the vectorizer)\n",
    "new_text_vector = tfidf_vectorizer.transform([new_text])\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "prediction = loaded_model.predict(new_text_vector)\n",
    "\n",
    "# Calculate cosine similarity between new text and training data\n",
    "cosine_similarity_score = cosine_similarity(new_text_vector, X_train).max()\n",
    "\n",
    "# Interpret the prediction and similarity score\n",
    "if prediction[0] == 0:\n",
    "    print(\"The text is not plagiarized.\")\n",
    "else:\n",
    "    print(f\"The text is plagiarized with a similarity score of {cosine_similarity_score*100:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88212e37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
